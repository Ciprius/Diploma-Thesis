Convolutional neural networks (CNNs) are very similar to a traditional artificial neural network, by retaining the same logic of the neuron of self-optimise through learning. Also, as traditional ANNs the neurons still receive an input and perform an operation (e.g. from a raw input image to a final output) \textcolor{green}{\sout{nu e musai sa procesezi imagini; CNN-urile pot procesa si alt fel de date!}}, the entire convolutional network will still consider a single discreet score function (weights). Moreover, all the regular stuff developed in an ANN still applies \cite{IntroCNN, 3dconvolutional}. \par

The main difference between these two types of neural network is in their layers. As the name suggests, a convolutional neural network, contains layers of convolution which are good at dealing with complex computations. Unlike CNNs, a classic ANN does not have such layer, thus making the calculations more complicated. Accordingly, a CNN is just an ANN with a special architecture which is better, as an example, at dealing with images.
\textcolor{red}{\sout{The main difference between these two types of neural network is that convolutional neural networks are generally used in recognition of patterns within images}}. \textcolor{green}{\sout{si o ann simpla poate fi aplciata pe imagini, dar lipsa convolutiilor, duce la rezultate slabe. Eu as zice ca diferenta intre ANN clasic si CNN e tipul de layere, deci CNN-ul e un ANN cu o arhitectura speciala; in plus CNN-urile se pot aplcia si pe text (cu convolutii pe text, adica filtre 1D) - vezi http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf, dar si pe grafe (cu convolutii specifice grafelor/arborilor). Iar in cazul procesarii imaginilor cu ANN, procesarea cu o ANN clasica ar tine cont doar de intensitatile pixelilor, pe cand un CNN tine cont si de pozitionarea lor (cine cu cine e vecin, nu doar ce valori au pixelii).}} Therefore, allows the encoding of image specific physiognomy within the architecture, thus making this king of networks better for image-related tasks \cite{IntroCNN, 3dconvolutional}. \par

One of the notable weakness of a traditional ANN is dealing with the computational complexity needed to calculate the data from an image. However, if the dimension of the photos is not large, take as an example the MMIST dataset which contains images of 28 $\times$ 28, all in black and white (this is translated as 28 $\times$ 28 $\times$ 1 which means the first hidden layer contains 784 weights), than it will be manageable by most ANNs. Thus, when an artificial or convolutional neural network becomes too complex, than two important problems pop up. The first one being the fact that having unlimited computational power is almost impossible and the second problem is dealing with overfitting. \textbf{Overfitting} appears when a neural network is not capable to learn thanks multiple reasons (e.g. fits the training data too well and unable to react as good at new data) \cite{IntroCNN}.See Figure \ref{fig:ex_overfit}. \par

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.39\linewidth]{Images/300px-Overfitting.png}
    \caption[Example of overfitting]{Example of overfitting, represented by the green line, whereas the black line represents a regularized model. Even though the green line follows better the training data, is too dependent on this data, thus making prediction difficult on new data \protect\footnotemark}
    \label{fig:ex_overfit}
\end{figure} \par

\footnotetext{image taken from: https://en.wikipedia.org/wiki/Overfitting\#/media/File:Overfitting.svg}

On the other hand, \textbf{underfitting} occurs when the model or algorithm does not fit the data well enough in the training phase. Thus, both overfitting and underfitting lead to a \textbf{poor prediction} on a new set of data.